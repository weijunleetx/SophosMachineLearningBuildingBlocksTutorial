
C:\Users\weijunlee\Desktop\SophosMachineLearningBuildingBlocksTutorial-master>dir
 Volume in drive C is Acer
 Volume Serial Number is 2872-7314

 Directory of C:\Users\weijunlee\Desktop\SophosMachineLearningBuildingBlocksTutorial-master

2018-06-28  07:09 PM    <DIR>          .
2018-06-28  07:09 PM    <DIR>          ..
2018-06-28  06:58 PM    <DIR>          data-new
2018-06-28  06:34 PM             2,307 README-new.md
2018-06-28  07:07 PM            10,929 urlmodel-new.py
...

C:\Users\weijunlee\Desktop\SophosMachineLearningBuildingBlocksTutorial-master>python urlmodel-new.py compare --filepath data-new --n 100000

Using TensorFlow backend.
06/28/2018 07:09:55 PM __main__     INFO     Importing clean URLs
06/28/2018 07:09:56 PM __main__     INFO     Importing dirty URLs
06/28/2018 07:09:56 PM __main__     INFO     Max dirty urls = 62286
06/28/2018 07:09:56 PM __main__     INFO     Dirty samples: 62286
06/28/2018 07:09:57 PM __main__     INFO     Clean samples: 436002
06/28/2018 07:10:05 PM __main__     INFO     MMH3-hashing feature vectors...
06/28/2018 07:11:57 PM __main__     INFO     MMH3-hashed data samples: 498288

06/28/2018 07:13:39 PM __main__     INFO     Try a deep model with time-split data ...
06/28/2018 07:13:39 PM __main__     INFO     Constructing model - deep
06/28/2018 07:13:41 PM __main__     INFO     Constructed model:
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 128)               384128
_________________________________________________________________
batch_normalization_1 (Batch (None, 128)               512
_________________________________________________________________
activation_1 (Activation)    (None, 128)               0
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 64)                8256
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0
_________________________________________________________________
dense_3 (Dense)              (None, 64)                4160
_________________________________________________________________
batch_normalization_3 (Batch (None, 64)                256
_________________________________________________________________
activation_3 (Activation)    (None, 64)                0
_________________________________________________________________
dropout_3 (Dropout)          (None, 64)                0
_________________________________________________________________
dense_4 (Dense)              (None, 32)                2080
_________________________________________________________________
batch_normalization_4 (Batch (None, 32)                128
_________________________________________________________________
activation_4 (Activation)    (None, 32)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 33
=================================================================
Total params: 399,809
Trainable params: 399,233
Non-trainable params: 576
_________________________________________________________________
06/28/2018 07:13:41 PM __main__     INFO     Start training model...
Epoch 1/20
326034/326034 [==============================] - 49s 149us/step - loss: 0.3288 - acc: 0.8856
Epoch 2/20
326034/326034 [==============================] - 29s 89us/step - loss: 0.2772 - acc: 0.9028
Epoch 3/20
326034/326034 [==============================] - 28s 87us/step - loss: 0.2576 - acc: 0.9097
Epoch 4/20
326034/326034 [==============================] - 28s 86us/step - loss: 0.2446 - acc: 0.9144
Epoch 5/20
326034/326034 [==============================] - 28s 85us/step - loss: 0.2334 - acc: 0.9185
Epoch 6/20
326034/326034 [==============================] - 35s 108us/step - loss: 0.2249 - acc: 0.9214
Epoch 7/20
326034/326034 [==============================] - 29s 90us/step - loss: 0.2165 - acc: 0.9243
Epoch 8/20
326034/326034 [==============================] - 29s 90us/step - loss: 0.2079 - acc: 0.9272
Epoch 9/20
326034/326034 [==============================] - 34s 105us/step - loss: 0.2018 - acc: 0.9294
Epoch 10/20
326034/326034 [==============================] - 30s 92us/step - loss: 0.1954 - acc: 0.9318
Epoch 11/20
326034/326034 [==============================] - 28s 87us/step - loss: 0.1886 - acc: 0.9338
Epoch 12/20
326034/326034 [==============================] - 29s 88us/step - loss: 0.1831 - acc: 0.9356
Epoch 13/20
326034/326034 [==============================] - 31s 95us/step - loss: 0.1770 - acc: 0.9376
Epoch 14/20
326034/326034 [==============================] - 31s 94us/step - loss: 0.1711 - acc: 0.9397
Epoch 15/20
326034/326034 [==============================] - 29s 89us/step - loss: 0.1644 - acc: 0.9419
Epoch 16/20
326034/326034 [==============================] - 29s 89us/step - loss: 0.1593 - acc: 0.9429
Epoch 17/20
326034/326034 [==============================] - 29s 89us/step - loss: 0.1546 - acc: 0.9452
Epoch 18/20
326034/326034 [==============================] - 30s 91us/step - loss: 0.1492 - acc: 0.9469
Epoch 19/20
326034/326034 [==============================] - 35s 107us/step - loss: 0.1425 - acc: 0.9490
Epoch 20/20
326034/326034 [==============================] - 30s 93us/step - loss: 0.1384 - acc: 0.9507
06/28/2018 07:24:02 PM __main__     INFO     Predicting test dataset... deep
06/28/2018 07:24:20 PM __main__     INFO     AUC = [0.9649943390253013]
06/28/2018 07:24:20 PM __main__     INFO     Plotting results for deep model @ data-new\deepmodel_timesplit
C:\Program Files\Python36\lib\site-packages\matplotlib\tight_layout.py:207: UserWarning: tight_layout : falling back to Agg renderer
  warnings.warn("tight_layout : falling back to Agg renderer")

06/28/2018 07:24:22 PM __main__     INFO     Try a shallow model with time-split data ...
06/28/2018 07:24:22 PM __main__     INFO     Constructing model - shallow
06/28/2018 07:24:22 PM __main__     INFO     Constructed model:
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_6 (Dense)              (None, 1)                 3001
=================================================================
Total params: 3,001
Trainable params: 3,001
Non-trainable params: 0
_________________________________________________________________
06/28/2018 07:24:22 PM __main__     INFO     Start training model...
Epoch 1/20
326034/326034 [==============================] - 24s 73us/step - loss: 0.3753 - acc: 0.8758
Epoch 2/20
326034/326034 [==============================] - 10s 32us/step - loss: 0.3270 - acc: 0.8829
Epoch 3/20
326034/326034 [==============================] - 9s 27us/step - loss: 0.3153 - acc: 0.8851
Epoch 4/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.3076 - acc: 0.8867
Epoch 5/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.3017 - acc: 0.8878
Epoch 6/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2971 - acc: 0.8891
Epoch 7/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2933 - acc: 0.8908
Epoch 8/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2901 - acc: 0.8924
Epoch 9/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2874 - acc: 0.8942
Epoch 10/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2851 - acc: 0.8955
Epoch 11/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2831 - acc: 0.8965
Epoch 12/20
326034/326034 [==============================] - 7s 22us/step - loss: 0.2813 - acc: 0.8970
Epoch 13/20
326034/326034 [==============================] - 9s 27us/step - loss: 0.2798 - acc: 0.8975
Epoch 14/20
326034/326034 [==============================] - 7s 21us/step - loss: 0.2784 - acc: 0.8980
Epoch 15/20
326034/326034 [==============================] - 7s 20us/step - loss: 0.2771 - acc: 0.8985
Epoch 16/20
326034/326034 [==============================] - 7s 20us/step - loss: 0.2760 - acc: 0.8989
Epoch 17/20
326034/326034 [==============================] - 7s 21us/step - loss: 0.2749 - acc: 0.9005
Epoch 18/20
326034/326034 [==============================] - 7s 21us/step - loss: 0.2740 - acc: 0.9020
Epoch 19/20
326034/326034 [==============================] - 7s 20us/step - loss: 0.2731 - acc: 0.9026
Epoch 20/20
326034/326034 [==============================] - 8s 24us/step - loss: 0.2723 - acc: 0.9035
06/28/2018 07:27:06 PM __main__     INFO     Predicting test dataset... shallow
06/28/2018 07:27:17 PM __main__     INFO     AUC = [0.7590635569352043]
06/28/2018 07:27:17 PM __main__     INFO     Plotting results for shallow model @ data-new\shallowmodel_timesplit

06/28/2018 07:28:36 PM __main__     INFO     Try a deep model with random-split data ...
06/28/2018 07:28:36 PM __main__     INFO     Constructing model - deep
06/28/2018 07:28:38 PM __main__     INFO     Constructed model:
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_7 (Dense)              (None, 128)               384128
_________________________________________________________________
batch_normalization_5 (Batch (None, 128)               512
_________________________________________________________________
activation_5 (Activation)    (None, 128)               0
_________________________________________________________________
dropout_5 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_8 (Dense)              (None, 64)                8256
_________________________________________________________________
batch_normalization_6 (Batch (None, 64)                256
_________________________________________________________________
activation_6 (Activation)    (None, 64)                0
_________________________________________________________________
dropout_6 (Dropout)          (None, 64)                0
_________________________________________________________________
dense_9 (Dense)              (None, 64)                4160
_________________________________________________________________
batch_normalization_7 (Batch (None, 64)                256
_________________________________________________________________
activation_7 (Activation)    (None, 64)                0
_________________________________________________________________
dropout_7 (Dropout)          (None, 64)                0
_________________________________________________________________
dense_10 (Dense)             (None, 32)                2080
_________________________________________________________________
batch_normalization_8 (Batch (None, 32)                128
_________________________________________________________________
activation_8 (Activation)    (None, 32)                0
_________________________________________________________________
dropout_8 (Dropout)          (None, 32)                0
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 33
=================================================================
Total params: 399,809
Trainable params: 399,233
Non-trainable params: 576
_________________________________________________________________
06/28/2018 07:28:38 PM __main__     INFO     Start training model...
Epoch 1/20
348801/348801 [==============================] - 65s 186us/step - loss: 0.2783 - acc: 0.9057
Epoch 2/20
348801/348801 [==============================] - 37s 107us/step - loss: 0.2268 - acc: 0.9235
Epoch 3/20
348801/348801 [==============================] - 36s 104us/step - loss: 0.2107 - acc: 0.9296
Epoch 4/20
348801/348801 [==============================] - 32s 93us/step - loss: 0.2001 - acc: 0.9325
Epoch 5/20
348801/348801 [==============================] - 30s 87us/step - loss: 0.1928 - acc: 0.9347
Epoch 6/20
348801/348801 [==============================] - 32s 91us/step - loss: 0.1859 - acc: 0.9369
Epoch 7/20
348801/348801 [==============================] - 29s 84us/step - loss: 0.1793 - acc: 0.9387
Epoch 8/20
348801/348801 [==============================] - 29s 84us/step - loss: 0.1736 - acc: 0.9405
Epoch 9/20
348801/348801 [==============================] - 29s 83us/step - loss: 0.1679 - acc: 0.9424
Epoch 10/20
348801/348801 [==============================] - 29s 84us/step - loss: 0.1627 - acc: 0.9439
Epoch 11/20
348801/348801 [==============================] - 29s 84us/step - loss: 0.1574 - acc: 0.9455
Epoch 12/20
348801/348801 [==============================] - 29s 83us/step - loss: 0.1527 - acc: 0.9466
Epoch 13/20
348801/348801 [==============================] - 29s 84us/step - loss: 0.1478 - acc: 0.9483
Epoch 14/20
348801/348801 [==============================] - 29s 83us/step - loss: 0.1428 - acc: 0.9499
Epoch 15/20
348801/348801 [==============================] - 29s 84us/step - loss: 0.1384 - acc: 0.9511
Epoch 16/20
348801/348801 [==============================] - 29s 83us/step - loss: 0.1331 - acc: 0.9529
Epoch 17/20
348801/348801 [==============================] - 28s 82us/step - loss: 0.1281 - acc: 0.9547
Epoch 18/20
348801/348801 [==============================] - 28s 81us/step - loss: 0.1243 - acc: 0.9557
Epoch 19/20
348801/348801 [==============================] - 29s 83us/step - loss: 0.1199 - acc: 0.9570
Epoch 20/20
348801/348801 [==============================] - 29s 82us/step - loss: 0.1151 - acc: 0.9586
06/28/2018 07:39:18 PM __main__     INFO     Predicting test dataset... deep
06/28/2018 07:39:34 PM __main__     INFO     AUC = [0.9468383394524416]
06/28/2018 07:39:34 PM __main__     INFO     Plotting results for deep model @ data-new\deepmodel_randsplit

06/28/2018 07:39:35 PM __main__     INFO     Try a shallow model with random-split data ...
06/28/2018 07:39:35 PM __main__     INFO     Constructing model - shallow
06/28/2018 07:39:35 PM __main__     INFO     Constructed model:
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_12 (Dense)             (None, 1)                 3001
=================================================================
Total params: 3,001
Trainable params: 3,001
Non-trainable params: 0
_________________________________________________________________
06/28/2018 07:39:35 PM __main__     INFO     Start training model...
Epoch 1/20
348801/348801 [==============================] - 21s 60us/step - loss: 0.3274 - acc: 0.8919
Epoch 2/20
348801/348801 [==============================] - 8s 23us/step - loss: 0.2749 - acc: 0.9052
Epoch 3/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2630 - acc: 0.9070
Epoch 4/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2557 - acc: 0.9093
Epoch 5/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2504 - acc: 0.9105
Epoch 6/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2462 - acc: 0.9106
Epoch 7/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2427 - acc: 0.9109
Epoch 8/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2397 - acc: 0.9120
Epoch 9/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2372 - acc: 0.9128
Epoch 10/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2350 - acc: 0.9135
Epoch 11/20
348801/348801 [==============================] - 7s 20us/step - loss: 0.2331 - acc: 0.9144
Epoch 12/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2314 - acc: 0.9163
Epoch 13/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2299 - acc: 0.9174
Epoch 14/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2286 - acc: 0.9192
Epoch 15/20
348801/348801 [==============================] - 8s 22us/step - loss: 0.2273 - acc: 0.9199
Epoch 16/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2262 - acc: 0.9202
Epoch 17/20
348801/348801 [==============================] - 8s 22us/step - loss: 0.2252 - acc: 0.9205
Epoch 18/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2243 - acc: 0.9209
Epoch 19/20
348801/348801 [==============================] - 8s 22us/step - loss: 0.2235 - acc: 0.9212
Epoch 20/20
348801/348801 [==============================] - 7s 21us/step - loss: 0.2227 - acc: 0.9214
06/28/2018 07:42:18 PM __main__     INFO     Predicting test dataset... shallow
06/28/2018 07:42:29 PM __main__     INFO     AUC = [0.8844793625316977]
06/28/2018 07:42:29 PM __main__     INFO     Plotting results for shallow model @ data-new\shallowmodel_randsplit

06/28/2018 07:42:30 PM __main__     INFO     Plotting all results...
06/28/2018 07:42:32 PM __main__     INFO     Done!
